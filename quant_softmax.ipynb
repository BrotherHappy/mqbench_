{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "softmax_quantLog创建完成\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'w_observer': 'MinMaxObserver', 'a_observer': 'EMAMinMaxObserver', 'w_fakequantize': 'FixedFakeQuantize', 'a_fakequantize': 'FixedFakeQuantize', 'w_qscheme': {'bit': 8, 'symmetry': True, 'per_channel': True, 'pot_scale': False}, 'a_qscheme': {'bit': 8, 'symmetry': True, 'per_channel': False, 'pot_scale': False}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MQBENCH] INFO: Quantize model Scheme: BackendType.Tensorrt Mode: Training\n",
      "[MQBENCH] INFO: Weight Quant Scheme is overrided!\n",
      "[MQBENCH] INFO: Activation Quant Scheme is overrided!\n",
      "[MQBENCH] INFO: Weight Qconfig:\n",
      "    FakeQuantize: FixedFakeQuantize Params: {}\n",
      "    Oberver:      MinMaxObserver Params: Symmetric: True / Bitwidth: 8 / Per channel: True / Pot scale: False / Extra kwargs: {}\n",
      "[MQBENCH] INFO: Activation Qconfig:\n",
      "    FakeQuantize: FixedFakeQuantize Params: {}\n",
      "    Oberver:      EMAMinMaxObserver Params: Symmetric: True / Bitwidth: 8 / Per channel: False / Pot scale: False / Extra kwargs: {}\n",
      "[MQBENCH] INFO: Replace module to qat module.\n",
      "[MQBENCH] INFO: Enable observer and Disable quantize.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 32/1563 [00:12<10:03,  2.54it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MQBENCH] INFO: Disable observer and Enable quantize.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 3/1563 [00:07<1:03:45,  2.45s/it]\n",
      "最终的精度是：0.0\n",
      "ori_最终的精度是：0.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import mqbench,torch,torchvision,numpy as np,matplotlib.pyplot as plt,torchvision,torchvision.models as models,timm,timm.models as models,torch.nn as nn\n",
    "from torchmetrics import ConfusionMatrix\n",
    "from plot import plot2dicts\n",
    "from mqbench.prepare_by_platform import prepare_by_platform\n",
    "from mqbench.prepare_by_platform import BackendType\n",
    "from mqbench.utils.state import enable_calibration\n",
    "from mqbench.utils.state import enable_quantization\n",
    "from mqbench.convert_deploy import convert_deploy\n",
    "from tqdm import tqdm\n",
    "from mqbench.utils.logger import logger as log\n",
    "from mqbench.fake_quantize.lsq import LearnableFakeQuantize\n",
    "from dataset import get_dataloader\n",
    "from timm.models.swin_transformer import SwinTransformer\n",
    "from logger import get_logger\n",
    "from mqbench.utils.registry import DEFAULT_MODEL_QUANTIZER\n",
    "from torch.fx.graph_module import GraphModule\n",
    "import timm.models.swin_transformer as st\n",
    "print(DEFAULT_MODEL_QUANTIZER)\n",
    "logger,workdir = get_logger(\"softmax_quant\")\n",
    "log = logger # \n",
    "\n",
    "device = torch.device('cuda')\n",
    "st.M = st.M.to(device)\n",
    "mean=np.array([123.675, 116.28, 103.53])/255\n",
    "std=np.array([58.395, 57.12, 57.375])/255\n",
    "\n",
    "# dataloader = get_dataloader() #\n",
    "extra_qconfig_dict = {\n",
    "    'w_observer': 'MinMaxObserver',\n",
    "    'a_observer': 'EMAMinMaxObserver',\n",
    "    # 'a_observer': 'MSEObserver',\n",
    "    'w_fakequantize': 'FixedFakeQuantize',\n",
    "    'a_fakequantize': 'FixedFakeQuantize',\n",
    "    # 'a_fakequantize': 'LearnableFakeQuantize',\n",
    "    # 'a_fakequantize': 'FixedFakeQuantize',\n",
    "    'w_qscheme': {\n",
    "        'bit': 8,\n",
    "        'symmetry': True,\n",
    "        'per_channel': True,\n",
    "        'pot_scale': False\n",
    "    },\n",
    "    'a_qscheme': {\n",
    "        'bit': 8,\n",
    "        'symmetry': True,\n",
    "        'per_channel': False,\n",
    "        'pot_scale': False\n",
    "    }\n",
    "}\n",
    "logger.info(extra_qconfig_dict) #  \n",
    "model = timm.create_model('swin_base_patch4_window7_224',pretrained=True).to(device) # 创建模型\n",
    "# model = timm.create_model('resnet18',pretrained=True).to(device) # 创建模型\n",
    "prepare_custom_config_dict = {'extra_qconfig_dict': extra_qconfig_dict}\n",
    "model = prepare_by_platform(model, BackendType.Tensorrt,prepare_custom_config_dict).to(device)\n",
    "ori= timm.create_model('swin_base_patch4_window7_224',pretrained=True).to(device) #\n",
    "model.eval() # 进行PTQ\n",
    "enable_calibration(model) # 打开校准\n",
    "dataloader = get_dataloader() #\n",
    "with torch.no_grad():\n",
    "    for i,(img,label) in enumerate(tqdm(dataloader)):\n",
    "        if i>=32:\n",
    "            break\n",
    "        img = img.to(device)\n",
    "        model(img)\n",
    "\n",
    "enable_quantization(model) # 打开量化，准备好模拟后台推断的量化\n",
    "ori.to(device)\n",
    "ori.eval()\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "from collections import defaultdict\n",
    "d_ori = defaultdict(list)\n",
    "d_quant = defaultdict(list)\n",
    "def hook_generator(d,name):\n",
    "    def hook(module,input,output):\n",
    "        d[name].append((input[0].detach().cpu().numpy(),output.detach().cpu().numpy()))\n",
    "        # d[name+'_output'].append(output.detach().cpu().numpy())\n",
    "        return output\n",
    "    return hook\n",
    "\n",
    "for name,m in ori.named_modules():\n",
    "    if name.endswith(\"softmax\"):\n",
    "        m.register_forward_hook(hook_generator(d_ori,name))\n",
    "\n",
    "for name,m in model.named_modules():\n",
    "    if name.endswith(\"softmax\"):\n",
    "        m.register_forward_hook(hook_generator(d_quant,name))\n",
    "\n",
    "# model = ori\n",
    "acc = Accuracy()\n",
    "acc_ori = Accuracy()\n",
    "with torch.no_grad():\n",
    "    for i,(img,label) in enumerate(tqdm(dataloader)):\n",
    "        if i>2:\n",
    "            break\n",
    "        img = img.to(device)\n",
    "        # acc.update(torch.argmax(model(img),dim=-1),torch.argmax(ori(img),dim=-1))\n",
    "        acc.update(model(img).detach().cpu(),label.cpu())\n",
    "        acc_ori.update(ori(img).detach().cpu(),label.cpu())\n",
    "# plot2dicts(d_ori,d_quant)\n",
    "logger.info(f\"最终的精度是：{acc.compute()}\")\n",
    "logger.info(f\"ori_最终的精度是：{acc_ori.compute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,m in model.named_modules():\n",
    "    if n.endswith('quantizer'):\n",
    "        display(n)\n",
    "        display(m.activation_post_process.min_val,m.activation_post_process.max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('mqbench')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e756b11dad8b54c319b836710bccded80b4f950f04fd6d62693d23f38aaddbf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
